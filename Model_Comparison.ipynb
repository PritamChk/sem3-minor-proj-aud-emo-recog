{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as prog_bar\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Loading model folders in a List\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1',\n",
       " 'model_2',\n",
       " 'model_3',\n",
       " 'model_4',\n",
       " 'model_5',\n",
       " 'model_6',\n",
       " 'simple@model_1',\n",
       " 'simple@model_2',\n",
       " 'simple@model_3']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_BASE_PATH = os.path.abspath('Models')\n",
    "model_folders = os.listdir(MODEL_BASE_PATH)\n",
    "model_folders = [f for f in model_folders if os.path.isdir(os.path.join(MODEL_BASE_PATH,f))]\n",
    "model_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54e96f86aff44509f9f22cd02f2cc43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = []\n",
    "model_names = []\n",
    "for folder in prog_bar(model_folders,total = len(model_folders)):\n",
    "    for model_file in os.listdir(os.path.join(MODEL_BASE_PATH,folder)):\n",
    "        models.append(\n",
    "                load_model(\n",
    "                        os.path.join(MODEL_BASE_PATH,folder,model_file),\n",
    "                        compile=True\n",
    "                    )\n",
    "            )\n",
    "        model_names.append(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1_50_50.h5',\n",
       " 'model_1_60_40.h5',\n",
       " 'model_1_75_25.h5',\n",
       " 'model_1_80_20.h5',\n",
       " 'model_2_50_50.h5',\n",
       " 'model_2_60_40.h5',\n",
       " 'model_2_75_25.h5',\n",
       " 'model_2_80_20.h5',\n",
       " 'model_3_50_50.h5',\n",
       " 'model_3_60_40.h5',\n",
       " 'model_3_75_25.h5',\n",
       " 'model_3_80_20.h5',\n",
       " 'model_4_50_50.h5',\n",
       " 'model_4_60_40.h5',\n",
       " 'model_4_75_25.h5',\n",
       " 'model_4_80_20.h5',\n",
       " 'model_5_50_50.h5',\n",
       " 'model_5_60_40.h5',\n",
       " 'model_5_75_25.h5',\n",
       " 'model_5_80_20.h5',\n",
       " 'model_6_50_50.h5',\n",
       " 'model_6_60_40.h5',\n",
       " 'model_6_75_25.h5',\n",
       " 'model_6_80_20.h5',\n",
       " 'simple@model_1_50_50.h5',\n",
       " 'simple@model_1_60_40.h5',\n",
       " 'simple@model_1_75_25.h5',\n",
       " 'simple@model_1_80_20.h5',\n",
       " 'simple@model_2_50_50.h5',\n",
       " 'simple@model_2_60_40.h5',\n",
       " 'simple@model_2_75_25.h5',\n",
       " 'simple@model_2_80_20.h5',\n",
       " 'simple@model_3_50_50.h5',\n",
       " 'simple@model_3_60_40.h5',\n",
       " 'simple@model_3_75_25.h5',\n",
       " 'simple@model_3_80_20.h5']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# loading of Final Test Data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>153</th>\n",
       "      <th>154</th>\n",
       "      <th>155</th>\n",
       "      <th>156</th>\n",
       "      <th>157</th>\n",
       "      <th>158</th>\n",
       "      <th>159</th>\n",
       "      <th>160</th>\n",
       "      <th>161</th>\n",
       "      <th>Y_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.229980</td>\n",
       "      <td>0.625852</td>\n",
       "      <td>0.608996</td>\n",
       "      <td>0.622792</td>\n",
       "      <td>0.622759</td>\n",
       "      <td>0.544743</td>\n",
       "      <td>0.482599</td>\n",
       "      <td>0.494714</td>\n",
       "      <td>0.565767</td>\n",
       "      <td>0.600405</td>\n",
       "      <td>...</td>\n",
       "      <td>2.196145e-03</td>\n",
       "      <td>2.405082e-03</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>1.051169e-04</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.189880</td>\n",
       "      <td>0.726748</td>\n",
       "      <td>0.730986</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.745474</td>\n",
       "      <td>0.644451</td>\n",
       "      <td>0.635654</td>\n",
       "      <td>0.655886</td>\n",
       "      <td>0.680437</td>\n",
       "      <td>0.731889</td>\n",
       "      <td>...</td>\n",
       "      <td>4.409507e-06</td>\n",
       "      <td>6.209365e-06</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.917692e-07</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.203365</td>\n",
       "      <td>0.747386</td>\n",
       "      <td>0.607909</td>\n",
       "      <td>0.577504</td>\n",
       "      <td>0.533079</td>\n",
       "      <td>0.527133</td>\n",
       "      <td>0.553211</td>\n",
       "      <td>0.556441</td>\n",
       "      <td>0.576028</td>\n",
       "      <td>0.593557</td>\n",
       "      <td>...</td>\n",
       "      <td>4.302234e-04</td>\n",
       "      <td>2.581176e-04</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>1.805856e-06</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.611220</td>\n",
       "      <td>0.611666</td>\n",
       "      <td>0.666117</td>\n",
       "      <td>0.671349</td>\n",
       "      <td>0.562674</td>\n",
       "      <td>0.410930</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.396894</td>\n",
       "      <td>0.442726</td>\n",
       "      <td>...</td>\n",
       "      <td>2.981484e-05</td>\n",
       "      <td>5.195718e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>3.697218e-06</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.235252</td>\n",
       "      <td>0.768608</td>\n",
       "      <td>0.764088</td>\n",
       "      <td>0.801592</td>\n",
       "      <td>0.791586</td>\n",
       "      <td>0.757175</td>\n",
       "      <td>0.690393</td>\n",
       "      <td>0.676488</td>\n",
       "      <td>0.669632</td>\n",
       "      <td>0.649580</td>\n",
       "      <td>...</td>\n",
       "      <td>4.535032e-07</td>\n",
       "      <td>8.242994e-07</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>1.401241e-07</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>0.145313</td>\n",
       "      <td>0.713982</td>\n",
       "      <td>0.657214</td>\n",
       "      <td>0.671235</td>\n",
       "      <td>0.661661</td>\n",
       "      <td>0.689820</td>\n",
       "      <td>0.618869</td>\n",
       "      <td>0.614723</td>\n",
       "      <td>0.656102</td>\n",
       "      <td>0.732271</td>\n",
       "      <td>...</td>\n",
       "      <td>6.337811e-06</td>\n",
       "      <td>2.894822e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.928386e-08</td>\n",
       "      <td>fearful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.184263</td>\n",
       "      <td>0.423081</td>\n",
       "      <td>0.474514</td>\n",
       "      <td>0.535139</td>\n",
       "      <td>0.471390</td>\n",
       "      <td>0.433355</td>\n",
       "      <td>0.487397</td>\n",
       "      <td>0.569050</td>\n",
       "      <td>0.693872</td>\n",
       "      <td>0.639250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.370115e-04</td>\n",
       "      <td>1.958906e-04</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2.745336e-06</td>\n",
       "      <td>sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.144878</td>\n",
       "      <td>0.601871</td>\n",
       "      <td>0.602785</td>\n",
       "      <td>0.626678</td>\n",
       "      <td>0.670229</td>\n",
       "      <td>0.704353</td>\n",
       "      <td>0.739067</td>\n",
       "      <td>0.730011</td>\n",
       "      <td>0.701652</td>\n",
       "      <td>0.682346</td>\n",
       "      <td>...</td>\n",
       "      <td>7.689643e-05</td>\n",
       "      <td>8.649582e-05</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.323215e-06</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>0.128251</td>\n",
       "      <td>0.631724</td>\n",
       "      <td>0.650544</td>\n",
       "      <td>0.715950</td>\n",
       "      <td>0.703636</td>\n",
       "      <td>0.695210</td>\n",
       "      <td>0.663834</td>\n",
       "      <td>0.596952</td>\n",
       "      <td>0.668593</td>\n",
       "      <td>0.679405</td>\n",
       "      <td>...</td>\n",
       "      <td>4.067244e-04</td>\n",
       "      <td>3.594477e-04</td>\n",
       "      <td>0.000404</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000120</td>\n",
       "      <td>1.015317e-05</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0.159961</td>\n",
       "      <td>0.462069</td>\n",
       "      <td>0.547367</td>\n",
       "      <td>0.562622</td>\n",
       "      <td>0.584216</td>\n",
       "      <td>0.578001</td>\n",
       "      <td>0.558278</td>\n",
       "      <td>0.651171</td>\n",
       "      <td>0.669523</td>\n",
       "      <td>0.646189</td>\n",
       "      <td>...</td>\n",
       "      <td>1.200017e-04</td>\n",
       "      <td>1.434326e-04</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>3.215064e-06</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>864 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6  \\\n",
       "0    0.229980  0.625852  0.608996  0.622792  0.622759  0.544743  0.482599   \n",
       "1    0.189880  0.726748  0.730986  0.749143  0.745474  0.644451  0.635654   \n",
       "2    0.203365  0.747386  0.607909  0.577504  0.533079  0.527133  0.553211   \n",
       "3    0.145937  0.611220  0.611666  0.666117  0.671349  0.562674  0.410930   \n",
       "4    0.235252  0.768608  0.764088  0.801592  0.791586  0.757175  0.690393   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "859  0.145313  0.713982  0.657214  0.671235  0.661661  0.689820  0.618869   \n",
       "860  0.184263  0.423081  0.474514  0.535139  0.471390  0.433355  0.487397   \n",
       "861  0.144878  0.601871  0.602785  0.626678  0.670229  0.704353  0.739067   \n",
       "862  0.128251  0.631724  0.650544  0.715950  0.703636  0.695210  0.663834   \n",
       "863  0.159961  0.462069  0.547367  0.562622  0.584216  0.578001  0.558278   \n",
       "\n",
       "            7         8         9  ...           153           154       155  \\\n",
       "0    0.494714  0.565767  0.600405  ...  2.196145e-03  2.405082e-03  0.001508   \n",
       "1    0.655886  0.680437  0.731889  ...  4.409507e-06  6.209365e-06  0.000007   \n",
       "2    0.556441  0.576028  0.593557  ...  4.302234e-04  2.581176e-04  0.000122   \n",
       "3    0.384422  0.396894  0.442726  ...  2.981484e-05  5.195718e-05  0.000038   \n",
       "4    0.676488  0.669632  0.649580  ...  4.535032e-07  8.242994e-07  0.000002   \n",
       "..        ...       ...       ...  ...           ...           ...       ...   \n",
       "859  0.614723  0.656102  0.732271  ...  6.337811e-06  2.894822e-06  0.000004   \n",
       "860  0.569050  0.693872  0.639250  ...  1.370115e-04  1.958906e-04  0.000408   \n",
       "861  0.730011  0.701652  0.682346  ...  7.689643e-05  8.649582e-05  0.000091   \n",
       "862  0.596952  0.668593  0.679405  ...  4.067244e-04  3.594477e-04  0.000404   \n",
       "863  0.651171  0.669523  0.646189  ...  1.200017e-04  1.434326e-04  0.000087   \n",
       "\n",
       "          156       157       158       159       160           161   Y_test  \n",
       "0    0.001496  0.001388  0.001705  0.002181  0.000971  1.051169e-04  disgust  \n",
       "1    0.000005  0.000004  0.000005  0.000004  0.000003  1.917692e-07      sad  \n",
       "2    0.000153  0.000184  0.000184  0.000210  0.000053  1.805856e-06      sad  \n",
       "3    0.000026  0.000081  0.000168  0.000324  0.000078  3.697218e-06  fearful  \n",
       "4    0.000004  0.000007  0.000010  0.000007  0.000002  1.401241e-07  fearful  \n",
       "..        ...       ...       ...       ...       ...           ...      ...  \n",
       "859  0.000006  0.000008  0.000009  0.000009  0.000002  8.928386e-08  fearful  \n",
       "860  0.000181  0.000085  0.000101  0.000071  0.000026  2.745336e-06      sad  \n",
       "861  0.000116  0.000117  0.000081  0.000058  0.000017  1.323215e-06  disgust  \n",
       "862  0.000418  0.000495  0.000389  0.000342  0.000120  1.015317e-05    angry  \n",
       "863  0.000072  0.000051  0.000099  0.000124  0.000047  3.215064e-06    happy  \n",
       "\n",
       "[864 rows x 163 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data_path = os.path.join('Features',\"Final_Test_Data.csv\")\n",
    "# test_data_path = os.path.join('Features',\"features_NORG.csv\")\n",
    "test_data_path = os.path.abspath(\"Train_Test_Data_Splits/tts_test_80_20.csv\")\n",
    "test_df = pd.read_csv(test_data_path,index_col = False)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y= test_df.iloc[:,:-1],pd.get_dummies(test_df['Y_test']) \n",
    "x_test = np.expand_dims(X, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 7ms/step - loss: 791.4243 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 727.7981 - accuracy: 0.1458\n",
      "Accuracy of our model on test data : 14.58%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 568.2112 - accuracy: 0.1725\n",
      "Accuracy of our model on test data : 17.25%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 493.5025 - accuracy: 0.1528\n",
      "Accuracy of our model on test data : 15.28%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1291.9298 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 1ms/step - loss: 929.1258 - accuracy: 0.1227\n",
      "Accuracy of our model on test data : 12.27%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1019.0740 - accuracy: 0.1192\n",
      "Accuracy of our model on test data : 11.92%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 1565.1915 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 1575.2941 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 1439.0017 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 2548.8088 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 2025.2985 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 1887.5741 - accuracy: 0.1667\n",
      "Accuracy of our model on test data : 16.67%\n",
      "27/27 [==============================] - 0s 9ms/step - loss: 931.7092 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 1666.4174 - accuracy: 0.1516\n",
      "Accuracy of our model on test data : 15.16%\n",
      "27/27 [==============================] - 0s 10ms/step - loss: 1489.2180 - accuracy: 0.1447\n",
      "Accuracy of our model on test data : 14.47%\n",
      "27/27 [==============================] - 1s 18ms/step - loss: 1161.2247 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 16ms/step - loss: 1703.4117 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 1166.5603 - accuracy: 0.1655\n",
      "Accuracy of our model on test data : 16.55%\n",
      "27/27 [==============================] - 0s 15ms/step - loss: 1710.0360 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 923.6622 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 861.1102 - accuracy: 0.1458\n",
      "Accuracy of our model on test data : 14.58%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 923.1259 - accuracy: 0.1331\n",
      "Accuracy of our model on test data : 13.31%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 974.0492 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 458.9619 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 306.3696 - accuracy: 0.1933\n",
      "Accuracy of our model on test data : 19.33%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 571.3438 - accuracy: 0.1447\n",
      "Accuracy of our model on test data : 14.47%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 578.0958 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 688.7087 - accuracy: 0.1447\n",
      "Accuracy of our model on test data : 14.47%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 619.5167 - accuracy: 0.1447\n",
      "Accuracy of our model on test data : 14.47%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 685.7308 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 2ms/step - loss: 910.8476 - accuracy: 0.1435\n",
      "Accuracy of our model on test data : 14.35%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 426.5945 - accuracy: 0.1493\n",
      "Accuracy of our model on test data : 14.93%\n",
      "27/27 [==============================] - 0s 7ms/step - loss: 775.5648 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n",
      "27/27 [==============================] - 0s 8ms/step - loss: 898.7319 - accuracy: 0.1481\n",
      "Accuracy of our model on test data : 14.81%\n",
      "27/27 [==============================] - 0s 6ms/step - loss: 731.7980 - accuracy: 0.1308\n",
      "Accuracy of our model on test data : 13.08%\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f\"Accuracy of our model on test data : { model.evaluate(x_test,y)[1]*100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25dd6ee6d223873db6918ba7dafc55ff354bee08d0006ede29dd28bdf8c1bd1c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
